---
title: "Appendix 2"
date: "Last updated: `r Sys.Date()`"
toc: true
header-includes:
  - \usepackage{float}
output: 
  rmarkdown::pdf_document:
    fig_caption: yes
    includes:
      in_header: preamble.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, messages = FALSE, warning = FALSE, cache = TRUE)
```

<!-- ## --------------------------- -->
<!-- ## Objective: -->
<!-- ##    - Imports species and covariate data -->
<!-- ##    - Scales covariates -->
<!-- ##    - Sets up data for NIMBLE -->
<!-- ## -->
<!-- ## Input: -->
<!-- ##    - functions/FXN-MVPv1.1.R -->
<!-- ##    - code/03-species-models/MVPv1.csv -->
<!-- ## -->
<!-- ## Output: -->
<!-- ##    - setup_BLOCK.rdata (saves environment for import to fit model) -->
<!-- ## -->
<!-- ## --------------------------- -->

\newpage
So you wanna fit an integrated species distribution model? You've come to the right place!

# NEED SOME SORT OF INTRO HERE.

Our workflow is separated into three parts.

- The first part of this sets up the range, imports species and covariate data, scales covariates, and sets everything up for NIMBLE.
- The second part fits the NIMBLE model.
- The third part summarizes the NIMBLE output and creates output figures.


Let's first load the libraries we'll need to set up, visualize, fit, and summarize our data.

```{r libraries, results = 'hide', message = F}
# Load libraries ----
library(tidyverse)
library(sf)
library(nimble)

## To install SpFut.flexiSDM or check for updates, use the commented code below:
# remotes::install_github("rileymummah/SpFut.flexiSDM", build_vignettes = T)
library(SpFut.flexiSDM)
library(SpFut.covariates)

## There are two custom functions that are needed to fit the data in NIMBLE
source("code/FXN-nimbleParallel.R")
```

# Part 1: 01-flexiSDM.R

## Load model specifications

Each model requires a variety of specifications. Rather than enter them manually in the code, we find it easier to manage multiple models by storing all specifications in a .csv file that is read in to provide input values. We call ours `model-specs.csv`. Each row represents a model, so you can easily see and edit the parameters used for each model. Let's load the .csv and take a look at how we structured it.

```{r model-specs}
mods <- read.csv("code/model-specs.csv")

head(mods)
```

The following table describes the column names, data type, and description found in `model-specs.csv`. Not all columns are required depending how you intend to fit the model (i.e., local computer vs. high performance computing cluster).

| Column Name     | Type      | Description                              |
|-----------------|-----------|------------------------------------------|
| number          | numeric   | Model number                             |
| sp.code         | character | Species code, must match the species code used in the species data                  |
| model           | character | Model name                               |
| mem.nim         | numeric   | Memory allocation (in MB) for NIMBLE. Could be omitted if not using an HPC. |
| mem.sum         | numeric   | Memory allocation (in MB) for parallelized summarization. Could be omitted if not using an HPC. |
| year.start      | numeric   | Starting year of data to include         |
| year.end        | numeric   | Ending year of data to include           |
| buffer          | numeric   | Size of buffer around range edge (in m)  |
| sp.auto         | logical   | Should a spatial model be included?      |
| zero_mean       | logical   | Should a zero mean assumption be included in the spatial model? |
| tau             | numeric/character | Assign a fixed value or a prior distribution in BUGS language for precision ($\tau$; e.g., dgamma(5,5)) |
| coarse.grid     | logical   | Should a coarse grid be used for the spatial model? Usually desired for large-range species |
| cont.grid       | logical   | Should the grid be restricted to continuous cells? (This will remove any groups of non-contiguous cells) |
| covs.PO         | character | A comma-separated list of covariates for modeling non-iNaturalist PO sampling effort. These must match the covariate names in the data. |
| covs.inat       | character | A comma-separated list of covariates for modeling iNaturalist sampling effort. These must match the covariate names in the data. |
| covs.lin        | character | A comma-separated list of linear covariates for modeling species relative abundance. These must match the covariate names in the data. |
| covs.quad       | character | A comma-separated list of quadratic covariates for modeling species relative abundance. These must match the covariate names in the data. |
| check.covs      | logical   | Should covariate selection remove multicollinearity? |
| Bprior          | character | Assign a prior distribution in BUGS lanaguage for the $\beta$ coefficients in the state model (e.g., dnorm(1,0))
| filter.region   | logical   | Should data outside of the region be removed? Note that this is only for mapping purposes; data that are outside of the region are never used to fit the model          |
| spat.bal        | logical   | Should the PO data be spatially balanced?         |
| coordunc        | numeric   | The level of acceptable coordinate uncertainty (for PO datasets that record coordinate uncertainty)    |
| coordunc_na.rm  | logical   | Should PO data with coordinate uncertainty = NA be removed? (for PO datasets that record coordinate uncertainty)|
| block.rows      | numeric   | The number of rows for cross-validation blocks    |
| block.cols      | numeric   | The number of columns for cross-validation blocks |
| block.folds     | numeric   | The number of folds to group cross-validation blocks into       |
| iter            | numeric   | The number of iterations to run an MCMC chain (the first 75% will be discarded as a burn-in)    |
| thin            | numeric   | Thin the MCMC chains by this parameter            |
| region.sub      | logical   | Only use the centroid of the region with a radius equal to the buffer size? |
| lon.hi          | numeric   | High longitude value to restrict the range
| lon.lo          | numeric   | Low longitude value to restrict the range
| lat.hi          | numeric   | High latitude value to restrict the range
| lat.lo          | numeric   | Low latitude value to restrict the range
| project         | numeric   | The number of future projections (otherwise, NA)  |
| exclude.dataset | character | A comma-separated list of datasets to exclude from analysis |


We have set up the scripts in the flexiSDM workflow so that a minimum number of parameters needs to be changed among them. To run this script in full (using our file arrangement), you only need to edit the following parameters:

```{r param.edit}
nums.do <- 3 # model number to run
block <- 'none' # CV fold to exclude ('none', 1, 2, or 3)
local <- 1 # are you running the code locally (1) or on an HPC (0)?
```


For the purposes of this demonstration, we're going to fit model 3, which uses a centroid of the Cascades frog (RACA) range with a 50,000km buffer. This will allow us to easily visualize the datasets and spatial grid, while maintaining local computational capabilities. You can see all of the specifications for this model in the third row of `mods`.



### Define model specifications

Now that we have loaded our model specifications, we can use them to define a series of inputs for the setup script (found in `01-flexiSDM.R`).

```{r mods}
## Set up model variables
mods <- filter(mods, number %in% nums.do)

## Get variables for model from model-specs.csv
number <- mods$number[1] # model number
sp.code <- mods$sp.code[1] # species code
model <- mods$model[1] # model name
sp.auto <- mods$sp.auto[1] # include spatial autocorrelation?
coarse.grid <- mods$coarse.grid[1] # use a coarse grid?
cont.grid <- mods$cont.grid[1] # restrict to only a continuous grid?
year.start <- mods$year.start[1] # start year for data
year.end <- mods$year.end[1] # end year for data
buffer <- mods$buffer[1] # buffer size (m)
filter.region <- mods$filter.region[1] # filter data to the region?
spat.bal <- mods$spat.bal[1] # include spatial balancing for PO data?
coordunc <- mods$coordunc[1] # level of coordinate uncertainty to include (m)
coordunc_na.rm <- mods$coordunc_na.rm[1] # include coordinate uncertainty = NA?
block.folds <- mods$block.folds[1] # how many groups of blocks?
block.rows <- mods$block.rows[1] # how many rows of blocks?
block.cols <- mods$block.cols[1] # how many columns of blocks?
block.out <- block # define the fold to setup

if (block.out == "none") {
  blockname <- "full" # rename the block to 'full' if not doing cross-validation
} else {blockname <- block.out} # otherwise, keep the block number

# names of datasets to exclude (e.g., iNaturalist) - must match file.label column in allfiles
exclude.dataset <- unlist(str_split(mods$exclude.dataset[1], pattern = ", "))

## ICAR parameters
zero_mean <- mods$zero_mean[1] # zero mean assumption?
tau <- mods$tau[1] # precision (tau) can be a fixed value or a prior

## MCMC parameters
iter <- mods$iter[1] # number of MCMC iterations
thin <- mods$thin[1] # number to thin by
burnin <- floor(iter*0.75) # burnin to discard

## Change of region
region.sub <- mods$region.sub[1] # only use the centroid + buffer?
lat.hi <- mods$lat.hi[1] # high value of latitude range
lat.lo <- mods$lat.lo[1] # low value of latitude range
lon.hi <- mods$lon.hi[1] # high value of longitude range
lon.lo <- mods$lon.lo[1] # low value of longitude range

## Future projections
project <- mods$project[1] # how many projections?
if (block.out != "none") {
  project <- 0 # no projections for cross-validation models
}

## Covariates
# list of non-iNaturalist PO covariates
covs.PO <- unlist(str_split(mods$covs.PO[1], pattern = ", "))
# list of iNaturalist covariates
covs.inat <- unlist(str_split(mods$covs.inat[1], pattern = ", "))
# list of linear covariates for state model
covs.lin <- unlist(str_split(mods$covs.lin[1], pattern = ", "))
# list of quadratic covariates for state model
covs.quad <- unlist(str_split(mods$covs.quad[1], pattern = ", "))
check.covs <- mods$check.covs[1] # covariate selection to remove multicollinearity?

## Define the prior for the state model coefficients
Bprior <- mods$Bprior[1]

## Combine linear and quadratic distribution covariates into covs.z
covs.z <- c(covs.lin, covs.quad)
if ("" %in% covs.z) {
  covs.z <- covs.z[-which(covs.z == "")]  
}
if (NA %in% covs.z) {
  covs.z <- covs.z[-which(is.na(covs.z))]
}
```


We're almost ready to set up the region and load data. Let's first ensure that we have output and data folders specific to the model we are fitting to store some of these objects.

```{r output-folder}
## Make output folder
out.dir <- paste0("outputs/", number, "_", sp.code, "_", model, "/")
if (dir.exists(out.dir) == F) {
  dir.create(out.dir)
}

## Make data folder
data.dir <- paste0("data/", number, "_", sp.code, "_", model, "/")
if (dir.exists(data.dir) == F) {
  dir.create(data.dir)
}
```




## Step 1: Define the region

We define the region of inference using the GAP and IUCN ranges. Other boundaries could be used to create the limits of the range. We saved the IUCN and GAP range boundaries in folders in `data/sp.code`, so that they can be called by the `get_range` function. We have also downloaded the US Census state boundary shapefile (`cb_2018_us_state_500k.shp`) to dictate the national and state borders. We have already overlaid a continental US hexbin grid (`conus.grid`). Unfortunately, this file is too large to upload to GitHub, so we demonstrate how we create the region and provide the file in `data.dir/region.rds` to bypass this step.

```{r ranges, results = 'hide'}
## Generating the region requires files that are too big for GitHub just read it in
if (file.exists(paste0(data.dir, "region.rds"))) {
  region <- read_rds(file = paste0(data.dir, "region.rds"))
} else {
  ## Load ranges
  range.path <- c(paste0("data/", sp.code, "/GAP/"),  
                  paste0("data/", sp.code, "/IUCN/"))
  range.name <- c("GAP", "IUCN")
  rangelist <- get_range(range.path,
                         range.name,
                         crs = 4326)
  # We use GAP and IUCN ranges, but you can use any polygons. Just enter the path to where you store the shape files
  
  ## USA boundary
  exclude <- c("Alaska", "Hawaii", "Commonwealth of the Northern Mariana Islands",
               "American Samoa", "United States Virgin Islands", "Guam", "Puerto Rico")
  usa <- st_read("../species-futures/data/USA/maps/cb_2018_us_state_500k/cb_2018_us_state_500k.shp") %>%
          filter((NAME %in% exclude) == F) %>%
          st_union()
  ## CONUS grid
  load("../species-futures/data/USA/grid-covar.rdata") # Too big for GitHub

  ## Region
  region <- make_region(rangelist,
                        buffer = buffer,
                        crs = 3857,
                        sub = region.sub,
                        boundary = usa,
                        grid = conus.grid,  # You can use any grid to delineate spatial units
                        rm.clumps = T,
                        clump.size = 50,
                        continuous = cont.grid)
  
  write_rds(region, file = paste0(data.dir, "region.rds"))
}
```

There is one additional step here if you intend to use a coarse spatial grid for the spatial model. Using a coarse grid improves computation time, which may be of concern for large-range species. We must redefine the spatial grid by grouping neighboring hexbins together in sets of seven via the `make_spatkey` function. Otherwise, `spatRegion` is set to NULL.

```{r spatRegion}
## If using the coarse spatial grid, redefine the grid and plot the resulting grid.
if (coarse.grid == T) {
  spatRegion <- suppressWarnings(make_spatkey(region$sp.grid))

  # Print spatial grid
  if (block.out == 'none') {
    pl <- ggplot(spatRegion$spat.grid) + geom_sf() + theme_bw()
    ggsave(pl, file = paste0(out.dir, "2_inputmap-e_spatGrid.jpg"), height = 8, width = 10)
  }
} else {
  spatRegion <- NULL
}
```



## Step 2: Designate training and testing data

We have set up the code so that this section needs to be run even if you do not intend to exclude data for cross-validation. If you do are not excluding any blocks, all of the data are considered "train" data. Otherwise, the data are split into "train" and "test" data depending on the cross-validation fold (1, 2, or 3) that is excluded.

```{r cv-blocks}

if (block.out == "none") { 
  # If fitting the full model, then there are no test data
  test.i <- c()            
  train.i <- region$sp.grid$conus.grid.id

} else {
  
  ## Set up cross validation blocks
  spatblocks <- make_CV_blocks(region, rows = block.rows, cols = block.cols, k = block.folds)

  block1 <- spatblocks %>% filter(folds == block.out)

  ## Find grid.ids for test block, everything else is in the training block
  test.i <- st_intersection(region$sp.grid, block1) %>%
             pull(conus.grid.id) %>%
             unique()
  train.i <- filter(region$sp.grid, conus.grid.id %in% test.i == F) %>%
              pull(conus.grid.id)
}
```


After the cross-validation blocks are assembled, the cells are assigned to "train" and "test" groups in a `gridkey`. This `gridkey` also contains `grid.id`, which allows us to index the data in NIMBLE.


```{r gridkey}
# Make gridkey ----
gridkey <- select(region$sp.grid, conus.grid.id) %>%
            st_drop_geometry() %>%
            mutate(grid.id = 1:nrow(.),
                   group = case_when(conus.grid.id %in% train.i ~ "train",
                                     conus.grid.id %in% test.i ~ "test"))
```




## Step 3: Load species data

We're now ready to load the species data. We have assembled a full amphibian species list (`model-specieslist.csv`) from which we pull out the common name, any species code that could refer to the species of interest, and the scientific name. We demonstrate how we do this with our list, but these values could be set manually or pulled from a different list. We additionally define the species type (e.g., Frog/Toad or Salamander) based off the genus name. This delineation is used later in the covariate data section.

```{r spp-codes}
## Define species codes
codeKey <- read.csv("data/model-specieslist.csv")

## Common name
common <- codeKey %>%
            filter(DS.code == sp.code) %>%
            pull(SSAR.common)
common

## All species codes used (some species are complexes or have subspecies so multiple codes exist)
sp.code.all <- codeKey %>%
                filter(DS.code == sp.code) %>%
                pull(all.codes)
sp.code.all

## Scientific name
sciname <- codeKey %>%
            filter(DS.code == sp.code) %>%
            pull(SSAR.scientific)
sciname

## Save genus name to assign Frog/Toad or Salamander
gen <- stringr::word(sciname, 1)

if (gen %in% c("Acris", "Anaxyrus", "Aquarana", "Ascaphus",
               "Craugastor", "Dendrobates", "Dryophytes", "Eleutherodactylus",
               "Gastrophryne", "Glandirana", "Hyla", "Hypopachus", "Incilius",
               "Leptodactylus", "Lithobates", "Osteopilus",
               "Pseudacris", "Rana", "Rhinella", "Rhinophrynus",
               "Scaphiopus", "Smilisca", "Spea", "Xenopus")) spp.type <- "Frog/Toad"
if (gen %in% c("Ambystoma", "Amphiuma", "Aneides", "Batrachoseps",
               "Cryptobranchus", "Desmognathus", "Dicamptodon",
               "Ensatina", "Eurycea", "Gyrinophilus", "Hemidactylium",
               "Hydromantes", "Necturus", "Notophthalmus",
               "Phaeognathus", "Plethodon", "Pseudobranchus",
               "Pseudotriton", "Rhyacotriton", "Siren",
               "Stereochilus", "Taricha", "Urspelerpes")) spp.type <- "Salamander"

gen; spp.type
```

Next we will load a dataframe with the names of data sources (`00-data-summary-flexiSDM.csv`). We define ours in a CSV file because we have hundreds of datasets to filter through for different species. This process could also be done by manually creating a dataframe with the same column names. The necessary columns are: `file.name` (how the file is named in the source folder), `file.label` (the label for the data source), data.type (Count, DND, or PO), PO.extent (does the presence-only span the continent or a particular state), `covar.mean` (detection covariates that should be averaged across passes), `covar.sum` (detection covariates that should be summed across passes). For additional clarification, sometimes it is more appropriate to summarize detection covariates by averaging than summing and vice versa. For example, the number of survey minutes should be summed but the temperature during the survey should be averaged. 
Note that the dataset names(s) included in `exclude.datasets` must match the `file.label` column.


```{r species-data}
# get all files that have data for that species
allfiles <- read.csv("data/00-data-summary-flexiSDM.csv") %>%
            filter(Species == sp.code) %>%
            rename(file.name = Data.Swamp.file.name,
                   file.label = Name,
                   covar.mean = Covar.mean,
                   covar.sum = Covar.sum,
                   data.type = Type.true) %>%
            select(file.name, file.label, covar.mean, covar.sum, 
                   data.type, PO.extent)

head(allfiles)
```

We can now use `allfiles` to load all of the species data sources. We have developed a function called `load_species_data` which takes the species code, `allfiles`, the region, and information about filtering, start/end dates, and spatial uncertainty to load and filter the data appropriately. The number of observations removed from each data source and the reasons for removal are provided as console output to the user. 


```{r load-species-data}
species.data <- load_species_data(sp.code,
                                  sp.code.all,
                                  file.info = allfiles,
                                  file.path = "data/data-ready/",
                                  region = region, 
                                  filter.region = filter.region,
                                  year.start = year.start,
                                  year.end = year.end,
                                  coordunc = coordunc,
                                  coordunc_na.rm = coordunc_na.rm,
                                  spat.thin = spat.bal,
                                  keep.conus.grid.id = gridkey$conus.grid.id[which(gridkey$group == "train")])

```




## Step 4: Plot species data

Next let's plot the species data to visualize where the data occur in the subrange.  

```{r plot-species-data-samples}
## Quick title to be used across figures
if (block == "none") {
  title <- ", full model"
} else {
  title <- paste0(", excluding block ", block)
}

## Plot data samples
pl <- map_species_data(region = region,
                       species.data = species.data,
                       year.start = year.start,
                       year.end = year.end,
                       plot = "samples",
                       plot.region = T,
                       details = F,
                       title = paste0(common, " (", sp.code, ")", title))

## Save plot
ggsave(pl, file = paste0(out.dir, "2_inputmap-a_data-", blockname, ".jpg"),
       height = 8, width = 10)
```


![Distribution of species data across the subrange](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/2_inputmap-a_data-full.jpg)

We can also take a look at the distribution of data across the cross-validation folds.


```{r cv-plots}
## Cross-validation block-specific plots
if (block.out != "none") {

  pl <- map_species_data(region = region,
                         species.data = species.data,
                         year.start = year.start,
                         year.end = year.end,
                         plot = "samples",
                         plot.blocks = T,
                         blocks = spatblocks[which(spatblocks$folds == block),],
                         plot.region = T,
                         details = F,
                         title = paste0(common, " (", sp.code, ")", title))
  ggsave(pl, file = paste0(out.dir, "2_inputmap-c_blocks-", blockname, ".jpg"),
         height = 8, width = 10)
} else {
  # Plot
  pl <- map_species_data(region = region,
                         species.data = species.data,
                         year.start = year.start,
                         year.end = year.end,
                         plot = "samples",
                         plot.blocks = T,
                         blocks = spatblocks,
                         plot.region = T,
                         details = F,
                         title = paste0(common, " (", sp.code, ")", title))
  ggsave(pl, file = paste0(out.dir, "2_inputmap-c_blocks-", blockname, ".jpg"),
         height = 8, width = 10)
}
```

![Distribution of data with overlaid cross-validation blocks](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/2_inputmap-c_blocks-full.jpg)

## Step 5: Load covariate data

We're now ready to download covariate data for the subrange. We use functions from the `SpFut.covariates` package. These functions consist of wrappers for other data sources (e.g., National Hydrologic Database IS THAT WHAT IT'S CALLED? and  the `geodata` R package) that download and format the data for our purposes. See the documentation for the `SpFut.covariates` package for more information on how to use the functions properly.

The `covar` object needs to contain all covariates needed for the distribution model (`covs.z`), as well as all covariates needed for the PO effort models (`covs.PO` and `covs.inat`). These covariates will vary across species. Any method can be used to derive the covariates, as long as it is aggregated to the spatial unit and included in `covar`.

DO WE WANT TO INCLUDE A DEMONSTRATION OF "OTHER INAT SPECIES" AS A COVARIATE OR SKIP IT IN THIS APPENDIX? - CLS says skip it. I added some text about other covariates being needed for other species 

Just a note: Downloading and assembling the covariate data can take significant time depending on the size of the range and your internet connection. We demonstrate how we downloaded the data below but provide the `covariates.rds` file to proceed to the next step.

```{r cov-data}
if (sp.code == "RACA") {
  
  if (file.exists(paste0(data.dir, "covariates.rds"))) {
    covar <- read_rds(paste0(data.dir, "covariates.rds"))
  } else {
    
    # Note that elevation data must be downloaded before running get_elevation()
    # We have downloaded the elevation and waterbody data outside of this repo
    # See documentation for details.
    tri <- get_elevation(locs = region$sp.grid, path = "../species-futures/data/USA/",
                         id.label = "conus.grid.id")
    waterbody <- get_waterbodies(locs = region$sp.grid, path = "../species-futures/data/USA/",
                                 id.label = "conus.grid.id")
    
    footprint <- get_footprint(locs = region$sp.grid, id.label = "conus.grid.id")
    climate <- get_climate(locs = region$sp.grid, id.label = "conus.grid.id")
    traveltime <- get_traveltime(locs = region$sp.grid, id.label = "conus.grid.id")
    
    covar <- full_join(tri, footprint, by = "conus.grid.id") %>%
              full_join(climate, by = "conus.grid.id") %>%
              full_join(waterbody, by = "conus.grid.id") %>%
              full_join(traveltime, by = "conus.grid.id") %>%
              mutate(sqrtarea_small = sqrt(area_small),
                     sqrtarea_medium = sqrt(area_medium)) %>%
              select(conus.grid.id, sqrtarea_small, sqrtarea_medium, 
                     footprint, TRI, tmin, traveltime)
    
    covar <- covar[order(match(covar$conus.grid.id, region$sp.grid$conus.grid.id)),]
    write_rds(covar, file = paste0(data.dir, "covariates.rds"))
    
  }
  
}
```

Next we remove grid cells that do not have complete covariates.

```{r incomplete-covs}
## Remove incomplete cases
rm <- which(complete.cases(covar[,covs.z]) == F)
if (length(rm) > 0) {
  covar <- covar[-rm,]
  region$sp.grid <- region$sp.grid[-rm,]
}
```

Then we scale all covariates to have a mean of 1 and a standard deviation of 0.

```{r scale-covs}
## Scale covariates 
covar_unscaled <- covar
numcols <- sapply(covar, is.numeric)
numcols <- which(numcols)
covar[,numcols] <- sapply(covar[,numcols], scale_this)
```

Finally we create the quadratic covariates (as defined in `model-specs.csv`).

```{r quad-covs}
if (length(covs.quad) > 0 & paste0(covs.quad, collapse = "") != "") {
  for (c in 1:length(covs.quad)) {
    covar[,paste0(covs.quad[c], "2")] <- covar[,covs.quad[c]] * covar[,covs.quad[c]]
    covs.z <- c(covs.z, paste0(covs.quad[c], "2"))
  }
}
```


There's one additional step that could be done here. If removing multicollinearity is desired, the following piece of code would check and remove covariates that violate a 0.4 correlation threshold. If there are fewer than 3 covariates remaining after the procedure, then a message will alert you.

```{r collinearity, eval=F}
# remove covariates that are correlated > 0.4
if (check.covs == T){

  threshold <- 0.4
  if (sp.code == "PJOR") threshold <- 0.45

  covs.rm <- select_covar(covs.z, threshold = threshold)
  covs.lin <- covs.lin[-which(covs.lin %in% covs.rm)]
  covs.quad <- covs.quad[-which(covs.quad %in% covs.rm)]

  covs.z <- c(covs.lin, covs.quad)
}

if (length(covs.z) < 3) {
  stop("There are fewer than 3 covariates remaining! This probably isn't a good model")
}
```


## Step 6: Plot covariates

Now that we've downloaded covariate data, let's take a look at the distribution of each covariate and the correlations between them.

```{r plot-covs, results = 'hide'}
if (block.out == "none") {
  
  ## Distribution covariates
  
  ## Define covariate labels
  covlabs <- read.csv("data/covariate-labels.csv") %>% filter(covariate %in% covs.z)
  
  plot_covar(covar,
             region,
             cov.names = covlabs$covariate,
             cov.labels = covlabs$Label,
             out.path = out.dir,
             out.name = "1_covariates-a_process-map")
  
  cor_covar(covar, 
            cov.names = covlabs$covariate,
            cov.labels = covlabs$Label,
            out.path = out.dir,
            out.name = "1_covariates-a_process-correlations", 
            color.threshold = 0.25)
  
  ## iNat covariates
  if ("iNaturalist" %in% names(species.data$obs)) {
    ## Define covariate labels
    covlabs <- read.csv("data/covariate-labels.csv") %>%
                filter(covariate %in% covs.inat)
    
    plot_covar(covar,
               region,
               cov.names = covlabs$covariate,
               cov.labels = covlabs$Label,
               out.path = out.dir,
               out.name = "1_covariates-b_iNat-map")
    
    if (length(covs.inat) > 1) {
      cor_covar(covar, 
                cov.names = covlabs$covariate,
                cov.labels = covlabs$Label,
                out.path = out.dir,
                out.name = "1_covariates-b_iNat-correlations", 
                color.threshold = 0.25)
    }
  }
  
  ## PO covs
  
  ## Define covariate labels
  covlabs <- read.csv("data/covariate-labels.csv") %>%
              filter(covariate %in% covs.PO)
  
  plot_covar(covar,
             region,
             cov.names = covlabs$covariate,
             cov.labels = covlabs$Label,
             out.path = out.dir,
             out.name = "1_covariates-c_PO-map")
  
  if (length(covs.PO) > 1) {
    cor_covar(covar, 
              cov.names = covlabs$covariate,
              cov.labels = covlabs$Label,
              out.path = out.dir,
              out.name = "1_covariates-c_PO-correlations", 
              color.threshold = 0.25)
  }
}
```


![Distribution of distribution-level covariates across the subrange](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/1_covariates-a_process-map.jpg)

![Correlation between distribution-level covariates](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/1_covariates-a_process-correlations.jpg)

![Distribution of presence-only (PO) effort covariates](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/1_covariates-c_PO-map.jpg)

## Step 7: NIMBLE

To load the data into NIMBLE, the data must be formatted in a specific way. We have wrapped this process in a function that combines and formats  species datasets (`allfiles`) and their associated covariates (contained in `allfiles`, `covs.inat`, and `covs.PO`)

```{r spdata}
sp.data <- sppdata_for_nimble(species.data,
                              region,
                              file.info = allfiles,
                              covar = covar,
                              covs.inat = covs.inat,
                              covs.PO = covs.PO,
                              DND.maybe = 1,  # treat "maybe" detections as 1 or 0?
                              # Only keep PO cells that training grid cells
                              keep.conus.grid.id = gridkey$conus.grid.id[which(gridkey$group == "train")]) 
```

Next, the distribution-level covariates (`covar`) are combined with the formatted species data. All of this is then broken into `data` and `constants` which are the inputs for the model.

```{r data-constants}
tmp <- data_for_nimble(sp.data, covar = covar, covs.z,
                       sp.auto = sp.auto, coarse.grid = coarse.grid, region = region,
                       process.intercept = F,
                       gridkey = gridkey, spatRegion = spatRegion)

data <- tmp$data
constants <- tmp$constants
```


The model structure allows for an indicator variable to indicate whether a cell is in a state with effort or not. There are generally two cases where this is useful. First, if a state agency has collected PO only from within its state. By definition, there is effort within that state but not outside of it. Second, in iNaturalist data, if a species has taxon geoprivacy (i.e., obscured locations due to listing status) within a state, records from that state will be removed due to high coordinate uncertainty. The effort in that state is therefore effectively 0. The following code adds the state indicator variable to `constants`.

```{r state-indicator}

# GPOR has taxon geoprivacy in four states
if (sp.code == "GPOR") obsc.state <- c("CT", "MS", "NJ", "RI")

# RACA has no iNat data
if (sp.code == "RACA") obsc.state <- NA


constants <- add_state_ind(species.data,
                           region,
                           gridkey,
                           constants,
                           covs.inat = covs.inat,
                           obsc.state = obsc.state,
                           keep.conus.grid.id = gridkey$conus.grid.id[which(gridkey$group == "train")])
```


### Code

```{r code}
code <- nimble_code(data,
                    constants, 
                    path = out.dir,
                    sp.auto = sp.auto, 
                    coarse.grid = coarse.grid,
                    Bprior = Bprior,
                    block.out = block.out,
                    min.visits.incl = 3, 
                    zero_mean = zero_mean,
                    rm.state = F,
                    tau = tau)
```

### Initial values

```{r inits}
inits <- function(x){nimble_inits(data,
                                  constants,
                                  sp.auto = sp.auto,
                                  seed = x)}
```


### Parameters

```{r params}
params <- nimble_params(data,
                        constants,
                        lambda = T,
                        XB = T,
                        sp.auto = sp.auto,
                        effort = T)
```


## Step 8: Clean up and save

```{r clean-up}
# Remove local and block in case the setup is run locally but the model is fit on the HPC.
# Remove other unnecessary files to reduce the size of setup_BLOCK.Rdata
rm(list=c('local','block','args','conus.covar.grid','conus.grid','usa','conus',
          'pl','centroid'))


# Save environment and full set up
save.image(paste0(out.dir, "setup_",block.out,".Rdata"))
```



<!-- # End script - proceed to 02-flexiSDM.R -->

<!-- ## --------------------------- -->
<!-- ## Objective:  -->
<!-- ##    - Fit NIMBLE model using setup_BLOCK.rdata file -->
<!-- ##  -->
<!-- ## Input: -->
<!-- ##    - setup_BLOCK.rdata -->
<!-- ## -->
<!-- ## Output:  -->
<!-- ##    - samples_BLOCK_CHAIN.rds OR samples_BLOCK.rds -->
<!-- ## -->
<!-- ## --------------------------- -->

# 02-flexiSDM.R

```{r param.edit2, eval = F}
num <- 3
block <- "none"
sp.code <- "RACA"
model <- "subrange"
chain <- 1
local <- 1
```


```{r load-packages2, results = 'hide', eval=F}
# Load functions and packages
source("functions/FXN-nimbleParallel.R") # HOW DO YOU RUN THIS IN ISDM-FRAMEWORK?
library(SpFut.flexiSDM)
```


```{r output-dir2, eval = F}
# Set output directory and load setup file
out.dir = paste0('outputs/',num,'_',sp.code,'_',model,'/')

load(paste0(out.dir,'setup_',block,'.Rdata'))
```

## Fit NIMBLE model

```{r fit-nimble, eval=F}
if (local == 1) {
  start.nim <- Sys.time()
  samples <- nimbleParallel(code = code,
                            data = data,
                            constants = constants,
                            inits = inits,
                            param = params,
                            iter = iter,
                            burnin = burnin,
                            thin = thin)

  end.nim <- Sys.time() - start.nim
  print(end.nim)

  saveRDS(samples, paste0(out.dir,'samples_',block,'.rds'))
} else {

  info <- list(seed = chain,
               inits = inits(chain))

  start.nim <- Sys.time()
  samples <- run_nimbleMCMC(info = info,
                            code = code,
                            constants = constants,
                            data = data,
                            param = params,
                            iter = iter,
                            burnin = burnin,
                            thin = thin)

  end.nim <- Sys.time() - start.nim
  print(end.nim)

  saveRDS(samples, paste0(out.dir,'samples_',block,'_',chain,'.rds'))
}
```



# 03-flexiSDM.R

<!-- <!-- ## --------------------------- --> -->
<!-- <!-- ## Objective:  --> -->
<!-- <!-- ##    - Fit NIMBLE model using setup_BLOCK.rdata file --> -->
<!-- <!-- ##  --> -->
<!-- <!-- ## Input: --> -->
<!-- <!-- ##    - setup_BLOCK.rdata --> -->
<!-- <!-- ##    - samples_BLOCK_CHAIN.rds OR samples_BLOCK.rds --> -->
<!-- <!-- ## --> -->
<!-- <!-- ## Output:  --> -->
<!-- <!-- ##    - samples_BLOCK_CHAIN.rds OR samples_BLOCK.rds --> -->
<!-- <!-- ## --> -->
<!-- <!-- ## --------------------------- --> -->


```{r load-packages3, results = 'hide', eval = F}
## load packages ----
library(tidyverse, quietly = T)
library(magrittr, quietly = T)
library(sf, quietly = T)
library(SpFut.flexiSDM)
```


```{r params.edit3, eval = F}
num <- 3
block <- "none"
sp.code <- "RACA"
model <- "subrange"
maxchain <- 3
local <- 1
```



```{r out.dir3, eval = F}
# load output directory, setup, and functions
out.dir = paste0('outputs/',num,'_',sp.code,'_',model,'/')

load(paste0(out.dir,'setup_',block,'.Rdata'))
```




```{r load-chains, eval = F}
# Load chains (samples) ----
samples <- readRDS(paste0(out.dir,'samples_',block,'.rds'))

## Calculate derived quantities ----
# This takes longer with the coarse grid.
samples <- lapply(samples, get_derived, data = data, project = project,
                  coarse.grid = coarse.grid, spatRegion = spatRegion,
                  pathToProj = 'code/03-species-models/setup-projections.R')
```

```{r summarize-chains, eval = F}
## Summarize chains ----
out <- summarize_samples(samples,
                         data,
                         constants,
                         project = project,
                         coarse.grid = coarse.grid,
                         block.out = block.out,
                         gridkey = gridkey,
                         spatkey = spatRegion$spatkey,
                         effort = T,
                         SLURM = ifelse(local == 1, F, T))

save(out, file = paste0(out.dir, "data", blockname, ".rdata"))
```


```{r plot-output, eval=F}
# Plot output ----

# Convergence
ggsave(plot_convergence(out),
       file = paste0(out.dir, "3_parameters-0_convergence-", block, ".jpg"),
       height = 5, width = 12)

if (block.out == "none") {
  cov.labs <- read.csv("data/covariate-labels.csv")

  ### Chains ----
  ggsave(plot_chains(samples, data = data, cov.labs = cov.labs,
                     plot = "B", cutoff = 0),
         file = paste0(out.dir, "3_parameters-a1_chains-B.jpg"),
         height = 6, width = 8)
  ggsave(plot_chains(samples, data = data, cov.labs = cov.labs,
                     plot = "alpha", cutoff = 0),
         file = paste0(out.dir, "3_parameters-b1_chains-alpha.jpg"),
         height = 6, width = 8)
  ggsave(plot_chains(samples, data = data, cov.labs = cov.labs,
                     plot = "tau", cutoff = 0),
         file = paste0(out.dir, "3_parameters-b1_chains-tau-",block,".jpg"),
         height = 6, width = 8)

  # Posteriors ----
  ggsave(plot_posteriors(samples, data = data, cov.labs = cov.labs,
                         plot = "B", cutoff = 0),
         file = paste0(out.dir, "3_parameters-a2_posteriors-B.jpg"),
         height = 6, width = 8)
  ggsave(plot_posteriors(samples, data = data, cov.labs = cov.labs,
                         plot = "alpha", cutoff = 0),
         file = paste0(out.dir, "3_parameters-b2_posteriors-alpha.jpg"),
         height = 6, width = 8)



  ### Parameter estimates ----
  ggsave(plot_pars(out,
                   plot.type = "full",
                   plot.group = "process",
                   title = "Process parameter estimates",
                   cov.labs = cov.labs),
         file = paste0(out.dir, "3_parameters-a3_B.jpg"),
         height = 6, width = 10)

  ggsave(plot_pars(out,
                   plot.type = "full",
                   plot.group = "dataset",
                   title = "Dataset parameter estimates"),
         file = paste0(out.dir, "3_parameters-b3_alpha.jpg"),
         height = 6, width = 10)

  ggsave(plot_pars(out,
                   plot.type = "full",
                   plot.group = "observation",
                   title = "Observation intercept estimates",
                   cov.labs = cov.labs),
         file = paste0(out.dir, "3_parameters-c3_observation.jpg"),
         height = 6, width = 10)

  ggsave(plot_pars(out,
                   plot.type = "full",
                   plot.group = "tau",
                   title = "Tau estimate"),
         file = paste0(out.dir, "3_parameters-c3_tau.jpg"),
         height = 6, width = 10)

  ### Marginal effects ----
  ggsave(plot_effects(data, out, breaks = 0.001),
         file = paste0(out.dir, "/3_parameters-a4-effects.jpg"),
         height = 7, width = 10)


  ### Maps ----
  # Current
  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "lambda",
                         out = out)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-a_lambda.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "lambda",
                         out = out,
                         plot.uncertainty = "unc.range")
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-a_lambda-uncabs.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "lambda",
                         out = out,
                         plot.uncertainty = "unc.rel")
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-a_lambda-uncrel.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "psi",
                         out = out)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-b_psi.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "psi",
                         out = out,
                         plot.uncertainty = "unc.range")
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-b_psi-uncabs.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "psi",
                         out = out,
                         plot.uncertainty = "unc.rel")
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-b_psi-uncrel.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "boundary",
                         out = out,
                         threshold = 0.25)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-c1_boundary-0.25.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "boundary",
                         out = out,
                         threshold = 0.5)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-c2_boundary-0.5.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "boundary",
                         out = out,
                         threshold = 0.75)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-c3_boundary-0.75.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "spat",
                         out = out,
                         coarse.grid = coarse.grid,
                         spatRegion = spatRegion)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-d_spat.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "XB",
                         out = out,
                         plot.exp = T)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-d_expXB.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "effort",
                         out = out)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-e_effort.jpg"),
         height = 7, width = 9)


  ### Future projections ----
  if (project > 0) {
    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-a_lambda.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           plot.uncertainty = "unc.range",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-a_lambda-uncabs.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           plot.uncertainty = "unc.rel",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-a_lambda-uncrel.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-b_psi.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           plot.uncertainty = "unc.range",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-b_psi-uncabs.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           plot.uncertainty = "unc.rel",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-b_psi-uncrel.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           threshold = 0.25,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-c1_boundary-0.25.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           threshold = 0.5,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-c2_boundary-0.5.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           threshold = 0.75,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-c3_boundary-0.75.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "XB",
                           out = out,
                           plot.exp = T,
                           plot.current = F,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-d_expXB-future.jpg"),
           height = 7, width = 9)


    ### Future absolute change ----
    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-a1_lambda-abs.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-b1_psi-abs.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           threshold = 0.25,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-c1_boundary-abs-0.25.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           threshold = 0.5,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-c2_boundary-abs-0.5.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           threshold = 0.75,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-c3_boundary-abs-0.75.jpg"),
           height = 7, width = 9)

    ### Future relative change ----
    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = "relative",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-a2_lambda-rel.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = "relative",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-b2_psi-rel.jpg"),
           height = 7, width = 9)
  }
}
```


































# High performance computing

We almost exclusively run these models on a high performance computing (HPC) cluster. We clone our repository directly to the HPC to ensure we have the same file structure and no version conflicts. We've set up the code so we can seamlessly move between running the workflow locally and on our HPC. 

To run the first steps of the workflow via `01-flexiSDM.R`, we call the script `01-flexiSDM.sh`, which takes 3 inputs: 

- Model number
- Block (defined by an array in the script)
- Local (1/0)

We have simplified this further by writing a wrapper called `01-HPC.sh`, which only takes one input: model number. Within the script, `local` is set to 0, indicating a run on an HPC.

The inputs provided to the `.sh` scripts are converted to inputs to the `01-flexiSDM.R` script and are interpreted below:

```{r hpc, eval = F}
# Converts command arguments to something interpretable by R
args = commandArgs(trailingOnly = TRUE)

if (length(args) > 0) {

  # Model number to run
  nums.do = as.numeric(args[1])

  # Blocks can be run as single jobs or as arrays
  block = as.numeric(args[2])
  
  # The block input is numeric only. Convert 4 = 'none'
  if (block == 4) {
    block <- 'none'
  }

  # Running locally? Yes = 1
  local = as.numeric(args[3])

  # If running on an HPC, set the working directory to the project home directory
  if (local == 0) {
    setwd('/home/directory/')
  }
}
```




<!-- args = commandArgs(trailingOnly = TRUE) -->

<!-- if (length(args) > 0) { -->
<!--   num = as.numeric(args[1]) -->
<!--   sp.code = as.character(args[2]) -->
<!--   model = as.character(args[3]) -->
<!--   block = as.numeric(args[4]) -->
<!--   chain = as.numeric(args[5]) -->
<!--   local = as.numeric(args[6])  -->

<!--   # If running on HPC, set working directory -->
<!--   if (local == 0) { -->
<!--     setwd('/caldera/hovenweep/projects/usgs/ecosystems/eesc/rmummah/species-futures/') -->
<!--   }  -->
<!-- } -->

<!-- # Ensure block is coded correctly -->
<!-- if (block == 4) { -->
<!--   block <- 'none' -->
<!-- } -->




<!-- # Setup ---- -->
<!-- args = commandArgs(trailingOnly = TRUE) -->

<!-- if (length(args) > 0) { -->
<!--   num = as.numeric(args[1]) -->
<!--   sp.code = as.character(args[2]) -->
<!--   model = as.character(args[3]) -->
<!--   block = as.numeric(args[4]) -->
<!--   maxchain = as.numeric(args[5]) -->
<!--   local = as.numeric(args[6]) -->

<!--   if (local == 0) { -->
<!--     setwd('/caldera/hovenweep/projects/usgs/ecosystems/eesc/rmummah/species-futures/') -->
<!--   }  -->

<!-- } -->

<!-- # Ensure block is coded correctly -->
<!-- if (block == 4) { -->
<!--   block <- 'none' -->
<!-- } -->