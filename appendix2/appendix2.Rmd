---
title: "Appendix 2"
date: "Last updated: `r Sys.Date()`"
toc: true
header-includes:
  - \usepackage{float}
output: 
  rmarkdown::pdf_document:
    fig_caption: yes
    includes:
      in_header: preamble.tex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, messages = FALSE, warning = FALSE, cache = TRUE)
```

<!-- ## --------------------------- -->
<!-- ## Objective: -->
<!-- ##    - Imports species and covariate data -->
<!-- ##    - Scales covariates -->
<!-- ##    - Sets up data for NIMBLE -->
<!-- ## -->
<!-- ## Input: -->
<!-- ##    - functions/FXN-MVPv1.1.R -->
<!-- ##    - code/03-species-models/MVPv1.csv -->
<!-- ## -->
<!-- ## Output: -->
<!-- ##    - setup_BLOCK.rdata (saves environment for import to fit model) -->
<!-- ## -->
<!-- ## --------------------------- -->

\newpage
So you wanna fit an integrated species distribution model? You've come to the right place!

# NEED SOME SORT OF INTRO HERE.

Our workflow is separated into four parts.

- First, the data needs to be in the correct format. We do not provide a script for this, as each dataset begins in a unique format. Instead, we provide a description of the format that the analysis requires.
- The first script sets up the range, imports species and covariate data, scales covariates, and sets everything up for NIMBLE.
- The second script fits the NIMBLE model.
- The third script summarizes the NIMBLE output and creates output figures.


Let's first load the libraries we'll need to set up, visualize, fit, and summarize our data.

```{r libraries, results = 'hide', message = F}
# Load libraries ----
library(tidyverse)
library(sf)
library(nimble)

## To install SpFut.flexiSDM or check for updates, use the commented code below:
# remotes::install_github("rileymummah/SpFut.flexiSDM", build_vignettes = T)
library(SpFut.flexiSDM)
library(SpFut.covariates)

## There are two custom functions that are needed to fit the data in NIMBLE
source("code/FXN-nimbleParallel.R")
```

# Part 0: Data formatting

Data must be in the following structure to enter models. This structure is suitable for Presence-only (PO), Detection/non-detection (DND), and count (Count) data. Other data types can usually be reduced into one of these types (e.g., capture-mark-recapture can be reduced to Count or DND). In anticipation of adding a specific observation model for CMR and time-to-detection data in the future, we include `individual.id` and `time.to.detection` as required columns in the data format.

We use a long format, where there is a unique row for each age (if recorded) of each species in each pass of each sampling event (defined as a visit to a site). There are 13 required columns. Any other information recorded in the field that relates to detection probability (e.g., duration of survey, area surveyed) should be included as additional columns. There should be no empty cells. Use NA (not NULL, -999, etc.) to indicate missing data.


| Column Name   | Format     | Appropriate values   | Notes            |
|---------------|------------|----------------------|------------------|
| site.id       | character  | alphanuermic string  | Each site.id is associated with exactly one set of coorinates|
| lat           | numeric    | WGS84                | Each set of coordinates is associated with exactly one site.id|
| lon           | numeric    | WGS84                | Each set of coordinates is associated with exactly one site.id|
| day           | numeric    | 1-31                 | If day was not recorded, use NA |
| month         | numeric    | 1-12                 | If month was not recorded, use NA |
| year          | numeric    | 4 digit year         | If year was not recorded, use NA |
| survey.conducted | numeric | 0, 1                 | Indicates whether or not a survey was conducted (e.g., if there was no water at an intended survey location, survey.conducted = 0). For all PO records, survey.conducted = 1 |
|survey.id      | numeric    | any number           | All observations from a single visit to a single site have the same survey.id  |
| data.type     | character  | `PO`, `DND`, `count`       | data.type may vary across species or age class (e.g. adults are count but larvae are DND) |
| pass.id       | numeric    | any number           | Within a survey.id (i.e., a visit to a site), each pass should have a unique pass.id. All observations within a pass should have the same pass.id |
| species       | character  | species identifier   | We use 4- or 6-digit codes. Any value can be used, as long as it is consistent across all datasets |
| age           | character  | `egg`, `egg mass`, `larva`, `juvenile`, `metamorph`, `adult`, `unknown`, `NR` | Use NR if age classes were not recorded. Do not use NA |
| individual.id | character  | alphanumeric string  | If no individuals were seen (count = 0), then individual.id = NA. If individuals were seen (count = 1) but not marked (too small, escaped, etc.), then individual.id = 0. | Applies only to CMR, otherwise use NA. |
| time.to.detect | numeric   | any number           | Use NA if time to detection was not recorded |
| count          | numeric   | If count: 0-Inf; If DND or CMR: 0/1/2; If PO: 1 | Must be a specific value, not range of numbers (e.g., 10-50); for DND and CMR, 0 = not detected, 1 = detected, 2 = maybe detected |

*A Note on survey.id and pass.id:* To make sure all data enter the model correctly, we need to know which records were part of the same sampling event. A sampling event is a specific visit to a specific site. Sampling events are identified with `survey.id`. During a sampling event, multiple observations (“passes”) may be made, e.g., multiple observers, multiple passes by a single observer, multiple audio recordings, multiple water samples for eDNA. Generally, site.id, day, month, and year define a unique sampling event. The exception is if passes occur overnight: passes that occur after midnight should be given the same survey.id as passes that occur before midnight.

All passes within a sampling event get the same survey.id. All passes within a sampling event get a unique pass.id.

Example: a double observer visual encounter survey. Both observations at Site A on Day 1 get survey.id = 1, and the observations by each observer get a pass.id that is unique within the survey.id (1 and 2). All observations at site B on Day 1 get survey.id = 2, and each observation gets a unique pass.id (1 and 2). Site A is revisited on Day 2, and all observations get survey.id = 3, and each observation gets a unique pass.id (1 and 2).

Example: five audio recordings are taken at each visit to a site. All five recordings at Site A on Day 1 get survey.id = 1, and each recording gets a pass.id from 1 to 5. All recordings at Site B on Day 1 get survey.id = 2, and each recording gets a pass.id from 1 to 5. Site A is revisited on Day 2, and all recordings get survey.id = 3, and each recording gets a pass.id from 1 to 5.

# Riley can you add the anotated data fig here please

# Part 1: 01-flexiSDM.R

## Load model specifications

Each model requires a variety of specifications. Rather than enter them manually in the code, we find it easier to manage multiple models by storing all specifications in a .csv file that is read in to provide input values. We call ours `model-specs.csv`. Each row represents a model, so you can easily see and edit the parameters used for each model. Let's load the .csv and take a look at how we structured it.

```{r model-specs}
mods <- read.csv("code/model-specs.csv")

head(mods)
```

The following table describes the column names, data type, and description found in `model-specs.csv`. Not all columns are required depending how you intend to fit the model (i.e., local computer vs. high performance computing cluster).

| Column Name     | Type      | Recommended value  | Description                              |
|-----------------|-----------|--------------------|------------------------------------------|
| number          | numeric   | 1                  | Model number                             |
| sp.code         | character | species identifier | Species code, must match the species code used in the species data |
| model           | character | short descriptor   | Model name                               |
| region.sub      | logical   | F, unless troubleshooting | Only use the centroid of the region with a radius equal to the buffer size? |
| buffer          | numeric   | 50000              | Size of buffer around range edge or centroid (in m)  |
| cont.grid       | logical   | T                  | Should the grid be restricted to continuous cells? (This will remove any groups of non-contiguous cells) |
| coarse.grid     | logical   | T, unless small region | Should a coarse grid be used for the spatial model? |
| lon.lo          | numeric   | empty, unless troubleshooting | Low longitude value to restrict the range |
| lon.hi          | numeric   | empty, unless troubleshooting |  High longitude value to restrict the range |
| lat.lo          | numeric   | empty, unless troubleshooting |  Low latitude value to restrict the range |
| lat.hi          | numeric   | empty, unless troubleshooting |  High latitude value to restrict the range |
| year.start      | numeric   | 1994               | Starting year of data to include         |
| year.end        | numeric   | current year       | Ending year of data to include           |
| filter.region   | logical   | F to see if species is recorded outside of range | Should data outside of the region be removed? Note that this is only for mapping purposes; data that are outside of the region are never used to fit the model          |
| spat.bal        | logical   | T                  |Should the PO data be spatially balanced?         |
| coordunc        | numeric   | 1000            | The level of acceptable coordinate uncertainty (meters, for PO datasets that record coordinate uncertainty)    |
| coordunc_na.rm  | logical   | T               | Should PO data with coordinate uncertainty = NA be removed? (for PO datasets that record coordinate uncertainty)|
| covs.PO         | character | human density   | A comma-separated list of covariates for modeling non-iNaturalist PO sampling effort. These must match the covariate names in the data. |
| covs.inat       | character | human density   | A comma-separated list of covariates for modeling iNaturalist sampling effort. These must match the covariate names in the data. |
| covs.lin        | character | based on species ecology | A comma-separated list of linear covariates for modeling species relative abundance. These must match the covariate names in the data. |
| covs.quad       | character | based on species ecology | A comma-separated list of quadratic covariates for modeling species relative abundance. These must match the covariate names in the data. |
| check.covs      | logical   | T               | Should covariate selection remove multicollinearity? |
| Bprior          | numeric or character | dnorm(0, 1) | Assign a prior distribution in BUGS language for the $\beta$ coefficients in the state model (e.g., dnorm(1,0))
| sp.auto         | logical   | T               | Should a spatial model be included?      |
| zero_mean       | logical   | T               | Should a zero mean assumption be included in the spatial model? |
| tau             | numeric or character | 1    | Assign a fixed value or a prior distribution in BUGS language for precision ($\tau$; e.g., dgamma(5,5)) |
| iter            | numeric   | depends on computational power | The number of iterations to run an MCMC chain (the first 75% will be discarded as a burn-in)    |
| thin            | numeric   | 5               | Thin the MCMC chains by this parameter            |
| project         | numeric   | 0               | The number of future projections (otherwise, NA)  |
| block.rows      | numeric   | 5               | The number of rows for cross-validation blocks    |
| block.cols      | numeric   | 5               | The number of columns for cross-validation blocks |
| block.folds     | numeric   | 3               | The number of folds to group cross-validation blocks into       |
| mem.nim         | numeric   | 30000           | Memory allocation (in MB) for NIMBLE. Can be omitted if not using an HPC. |
| mem.sum         | numeric   | 40000           | Memory allocation (in MB) for parallelized summarization. Can be omitted if not using an HPC. |

We have set up the scripts in the flexiSDM workflow so that a minimum number of parameters needs to be changed among them. To run this script in full (using our file arrangement), you only need to edit the following parameters:

```{r param.edit}
nums.do <- 3 # model number to run
fold <- 'none' # CV fold to exclude ('none', 1, 2, or 3)
local <- 1 # are you running the code locally (1) or on an HPC (0)?
```


For the purposes of this demonstration, we're going to fit model 3, which uses a centroid of the Cascades frog (RACA) range with a 50,000km buffer. This will allow us to easily visualize the datasets and spatial grid, while maintaining local computational capabilities. You can see all of the specifications for this model in the third row of `mods`.



### Define model specifications

Now that we have loaded our model specifications, we can use them to define a series of inputs for the setup script (found in `01-flexiSDM.R`).

```{r mods}
## Set up model variables
mods <- filter(mods, number %in% nums.do)

## Get variables for model from model-specs.csv
number <- mods$number[1] # model number
sp.code <- mods$sp.code[1] # species code
model <- mods$model[1] # model name
sp.auto <- mods$sp.auto[1] # include spatial autocorrelation?
coarse.grid <- mods$coarse.grid[1] # use a coarse grid?
cont.grid <- mods$cont.grid[1] # restrict to only a continuous grid?
year.start <- mods$year.start[1] # start year for data
year.end <- mods$year.end[1] # end year for data
buffer <- mods$buffer[1] # buffer size (m)
filter.region <- mods$filter.region[1] # filter data to the region?
spat.bal <- mods$spat.bal[1] # include spatial balancing for PO data?
coordunc <- mods$coordunc[1] # level of coordinate uncertainty to include (m)
coordunc_na.rm <- mods$coordunc_na.rm[1] # include coordinate uncertainty = NA?
block.folds <- mods$block.folds[1] # how many groups of blocks?
block.rows <- mods$block.rows[1] # how many rows of blocks?
block.cols <- mods$block.cols[1] # how many columns of blocks?
fold.out <- fold # define the fold to setup

if (fold.out == "none") {
  blockname <- "full" # rename the fold to 'full' if not doing cross-validation
} else {blockname <- fold.out} # otherwise, keep the fold number

## ICAR parameters
zero_mean <- mods$zero_mean[1] # zero mean assumption?
tau <- mods$tau[1] # precision (tau) can be a fixed value or a prior

## MCMC parameters
iter <- mods$iter[1] # number of MCMC iterations
thin <- mods$thin[1] # number to thin by
burnin <- floor(iter*0.75) # burnin to discard

## Change of region
region.sub <- mods$region.sub[1] # only use the centroid + buffer?
lat.hi <- mods$lat.hi[1] # high value of latitude range
lat.lo <- mods$lat.lo[1] # low value of latitude range
lon.hi <- mods$lon.hi[1] # high value of longitude range
lon.lo <- mods$lon.lo[1] # low value of longitude range

## Future projections
project <- mods$project[1] # how many projections?
if (fold.out != "none") {
  project <- 0 # no projections for cross-validation models
}

## Covariates
# list of non-iNaturalist PO covariates
covs.PO <- unlist(str_split(mods$covs.PO[1], pattern = ", "))
# list of iNaturalist covariates
covs.inat <- unlist(str_split(mods$covs.inat[1], pattern = ", "))
# list of linear covariates for state model
covs.lin <- unlist(str_split(mods$covs.lin[1], pattern = ", "))
# list of quadratic covariates for state model
covs.quad <- unlist(str_split(mods$covs.quad[1], pattern = ", "))
check.covs <- mods$check.covs[1] # covariate selection to remove multicollinearity?

## Define the prior for the state model coefficients
Bprior <- mods$Bprior[1]

## Combine linear and quadratic distribution covariates into covs.z
covs.z <- c(covs.lin, covs.quad)
if ("" %in% covs.z) {
  covs.z <- covs.z[-which(covs.z == "")]  
}
if (NA %in% covs.z) {
  covs.z <- covs.z[-which(is.na(covs.z))]
}
```


We're almost ready to set up the region and load data. Let's first ensure that we have output and data folders specific to the model we are fitting to store some of these objects.

```{r output-folder}
## Make output folder
out.dir <- paste0("outputs/", number, "_", sp.code, "_", model, "/")
if (dir.exists(out.dir) == F) {
  dir.create(out.dir)
}

## Make data folder
data.dir <- paste0("data/", number, "_", sp.code, "_", model, "/")
if (dir.exists(data.dir) == F) {
  dir.create(data.dir)
}
```




## Step 1: Define the region

We define the region of inference using the GAP and IUCN ranges. Other boundaries could be used to create the limits of the range. We saved the IUCN and GAP range boundaries in folders in `data/sp.code`, so that they can be called by the `get_range` function. We have also downloaded the US Census state boundary shapefile (`cb_2018_us_state_500k.shp`) to dictate the national and state borders. We have already overlaid a continental US hexbin grid (`conus.grid`). Unfortunately, this file is too large to upload to GitHub, so we demonstrate how we create the region and provide the file in `data.dir/region.rds` to bypass this step.

```{r ranges, results = 'hide'}
## Generating the region requires files that are too big for GitHub just read it in
if (file.exists(paste0(data.dir, "region.rds"))) {
  region <- read_rds(file = paste0(data.dir, "region.rds"))
} else {
  ## Load ranges
  range.path <- c(paste0("data/", sp.code, "/GAP/"),  
                  paste0("data/", sp.code, "/IUCN/"))
  range.name <- c("GAP", "IUCN")
  rangelist <- get_range(range.path,
                         range.name,
                         crs = 4326)
  # We use GAP and IUCN ranges, but you can use any polygons. Just enter the path to where you store the shape files
  
  ## USA boundary
  exclude <- c("Alaska", "Hawaii", "Commonwealth of the Northern Mariana Islands",
               "American Samoa", "United States Virgin Islands", "Guam", "Puerto Rico")
  usa <- st_read("../species-futures/data/USA/maps/cb_2018_us_state_500k/cb_2018_us_state_500k.shp") %>%
          filter((NAME %in% exclude) == F) %>%
          st_union()
  ## CONUS grid
  load("../species-futures/data/USA/grid-covar.rdata") # Too big for GitHub

  ## Region
  region <- make_region(rangelist,
                        buffer = buffer,
                        crs = 3857,
                        sub = region.sub,
                        boundary = usa,
                        grid = conus.grid,  # You can use any grid to delineate spatial units
                        rm.clumps = T,
                        clump.size = 50,
                        continuous = cont.grid)
  
  write_rds(region, file = paste0(data.dir, "region.rds"))
}
```

There is one additional step here if you intend to use a coarse spatial grid for the spatial model. Using a coarse grid improves computation time, which may be of concern for large-range species. We must redefine the spatial grid by grouping neighboring hexbins together in sets of seven via the `make_spatkey` function. Otherwise, `spatRegion` is set to NULL.

```{r spatRegion}
## If using the coarse spatial grid, redefine the grid and plot the resulting grid.
if (coarse.grid == T) {
  spatRegion <- suppressWarnings(make_spatkey(region$sp.grid))

  # Print spatial grid
  if (fold.out == 'none') {
    pl <- ggplot(spatRegion$spat.grid) + geom_sf() + theme_bw()
    ggsave(pl, file = paste0(out.dir, "2_inputmap-e_spatGrid.jpg"), height = 8, width = 10)
  }
} else {
  spatRegion <- NULL
}
```



## Step 2: Designate training and testing data

We have set up the code so that this section needs to be run even if you do not intend to exclude data for cross-validation. If you do are not excluding any blocks, all of the data are considered "train" data. Otherwise, the data are split into "train" and "test" data depending on the cross-validation fold (1, 2, or 3) that is excluded.

```{r cv-blocks}

if (fold.out == "none") { 
  # If fitting the full model, then there are no test data
  test.i <- c()            
  train.i <- region$sp.grid$conus.grid.id

} else {
  
  ## Set up cross validation blocks
  spatblocks <- make_CV_blocks(region, rows = block.rows, cols = block.cols, k = block.folds)

  block1 <- spatblocks %>% filter(folds == fold.out)

  ## Find grid.ids for test fold, everything else is in the training fold
  test.i <- st_intersection(region$sp.grid, block1) %>%
             pull(conus.grid.id) %>%
             unique()
  train.i <- filter(region$sp.grid, conus.grid.id %in% test.i == F) %>%
              pull(conus.grid.id)
}
```


After the cross-validation blocks are assembled, the cells are assigned to "train" and "test" groups in a `gridkey`. This `gridkey` also contains `grid.id`, which allows us to index the data in NIMBLE.


```{r gridkey}
# Make gridkey ----
gridkey <- select(region$sp.grid, conus.grid.id) %>%
            st_drop_geometry() %>%
            mutate(grid.id = 1:nrow(.),
                   group = case_when(conus.grid.id %in% train.i ~ "train",
                                     conus.grid.id %in% test.i ~ "test"))
```




## Step 3: Load species data

We're now ready to load the species data. We have assembled a full amphibian species list (`model-specieslist.csv`) from which we pull out the common name, any species code that could refer to the species of interest, and the scientific name. We demonstrate how we do this with our list, but these values could be set manually or pulled from a different list. We additionally define the species type (e.g., Frog/Toad or Salamander) based off the genus name. This delineation is used later in the covariate data section.

```{r spp-codes}
## Define species codes
codeKey <- read.csv("data/model-specieslist.csv")

## Common name
common <- codeKey %>%
            filter(DS.code == sp.code) %>%
            pull(SSAR.common)
common

## All species codes used (some species are complexes or have subspecies so multiple codes exist)
sp.code.all <- codeKey %>%
                filter(DS.code == sp.code) %>%
                pull(all.codes)
sp.code.all

## Scientific name
sciname <- codeKey %>%
            filter(DS.code == sp.code) %>%
            pull(SSAR.scientific)
sciname

## Save genus name to assign Frog/Toad or Salamander
spp.type <- codeKey %>%
            filter(DS.code == sp.code) %>%
            pull(spp.type)
spp.type
```

Next we will load a dataframe with the names of data sources (`00-data-summary-flexiSDM.csv`). We define ours in a CSV file because we have hundreds of datasets to filter through for different species. This process could also be done by manually creating a dataframe with the same column names. The necessary columns are: `file.name` (how the file is named in the source folder), `file.label` (the label for the data source), data.type (Count, DND, or PO), PO.extent (does the presence-only span the continent or a particular state), `covar.mean` (detection covariates that should be averaged across passes), `covar.sum` (detection covariates that should be summed across passes). For additional clarification, sometimes it is more appropriate to summarize detection covariates by averaging than summing and vice versa. For example, the number of survey minutes should be summed but the temperature during the survey should be averaged. 
Note that the dataset names(s) included in `exclude.datasets` must match the `file.label` column.


```{r species-data}
# get all files that have data for that species
allfiles <- read.csv("data/00-data-summary-flexiSDM.csv") %>%
            filter(Species == sp.code) %>%
            rename(file.name = Data.Swamp.file.name,
                   file.label = Name,
                   covar.mean = Covar.mean,
                   covar.sum = Covar.sum,
                   data.type = Type.true) %>%
            select(file.name, file.label, covar.mean, covar.sum, 
                   data.type, PO.extent)

head(allfiles)
```

We can now use `allfiles` to load all of the species data sources. We have developed a function called `load_species_data` which takes the species code, `allfiles`, the region, and information about filtering, start/end dates, and spatial uncertainty to load and filter the data appropriately. The number of observations removed from each data source and the reasons for removal are provided as console output to the user. 


```{r load-species-data}
species.data <- load_species_data(sp.code,
                                  sp.code.all,
                                  file.info = allfiles,
                                  file.path = "data/data-ready/",
                                  region = region, 
                                  filter.region = filter.region,
                                  year.start = year.start,
                                  year.end = year.end,
                                  coordunc = coordunc,
                                  coordunc_na.rm = coordunc_na.rm,
                                  spat.thin = spat.bal,
                                  keep.conus.grid.id = gridkey$conus.grid.id[which(gridkey$group == "train")])

```




## Step 4: Plot species data

Next let's plot the species data to visualize where the data occur in the subrange.  

```{r plot-species-data-samples}
## Quick title to be used across figures
if (fold == "none") {
  title <- ", full model"
} else {
  title <- paste0(", excluding fold ", fold)
}

## Plot data samples
pl <- map_species_data(region = region,
                       species.data = species.data,
                       year.start = year.start,
                       year.end = year.end,
                       plot = "samples",
                       plot.region = T,
                       details = F,
                       title = paste0(common, " (", sp.code, ")", title))

## Save plot
ggsave(pl, file = paste0(out.dir, "2_inputmap-a_data-", blockname, ".jpg"),
       height = 8, width = 10)
```


![Distribution of species data across the subrange](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/2_inputmap-a_data-full.jpg)

We can also take a look at the distribution of data across the cross-validation folds.


```{r cv-plots}
## Cross-validation fold-specific plots
if (fold.out != "none") {

  pl <- map_species_data(region = region,
                         species.data = species.data,
                         year.start = year.start,
                         year.end = year.end,
                         plot = "samples",
                         plot.blocks = T,
                         blocks = spatblocks[which(spatblocks$folds == fold),],
                         plot.region = T,
                         details = F,
                         title = paste0(common, " (", sp.code, ")", title))
  ggsave(pl, file = paste0(out.dir, "2_inputmap-c_blocks-", blockname, ".jpg"),
         height = 8, width = 10)
} else {
  # Plot
  pl <- map_species_data(region = region,
                         species.data = species.data,
                         year.start = year.start,
                         year.end = year.end,
                         plot = "samples",
                         plot.blocks = T,
                         blocks = spatblocks,
                         plot.region = T,
                         details = F,
                         title = paste0(common, " (", sp.code, ")", title))
  ggsave(pl, file = paste0(out.dir, "2_inputmap-c_blocks-", blockname, ".jpg"),
         height = 8, width = 10)
}
```

![Distribution of data with overlaid cross-validation blocks](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/2_inputmap-c_blocks-full.jpg)

## Step 5: Load covariate data

We're now ready to download covariate data for the subrange. We use functions from the `SpFut.covariates` package. These functions consist of wrappers for other data sources (e.g., National Hydrologic Database IS THAT WHAT IT'S CALLED? and  the `geodata` R package) that download and format the data for our purposes. See the documentation for the `SpFut.covariates` package for more information on how to use the functions properly.

The `covar` object needs to contain all covariates needed for the distribution model (`covs.z`), as well as all covariates needed for the PO effort models (`covs.PO` and `covs.inat`). These covariates will vary across species. Any method can be used to derive the covariates, as long as it is aggregated to the spatial unit and included in `covar`.

DO WE WANT TO INCLUDE A DEMONSTRATION OF "OTHER INAT SPECIES" AS A COVARIATE OR SKIP IT IN THIS APPENDIX? - CLS says skip it. I added some text about other covariates being needed for other species 

Just a note: Downloading and assembling the covariate data can take significant time depending on the size of the range and your internet connection. We demonstrate how we downloaded the data below but provide the `covariates.rds` file to proceed to the next step.

```{r cov-data}
if (sp.code == "RACA") {
  
  if (file.exists(paste0(data.dir, "covariates.rds"))) {
    covar <- read_rds(paste0(data.dir, "covariates.rds"))
  } else {
    
    # Note that elevation data must be downloaded before running get_elevation()
    # We have downloaded the elevation and waterbody data outside of this repo
    # See documentation for details.
    tri <- get_elevation(locs = region$sp.grid, path = "../species-futures/data/USA/",
                         id.label = "conus.grid.id")
    waterbody <- get_waterbodies(locs = region$sp.grid, path = "../species-futures/data/USA/",
                                 id.label = "conus.grid.id")
    
    footprint <- get_footprint(locs = region$sp.grid, id.label = "conus.grid.id")
    climate <- get_climate(locs = region$sp.grid, id.label = "conus.grid.id")
    traveltime <- get_traveltime(locs = region$sp.grid, id.label = "conus.grid.id")
    
    covar <- full_join(tri, footprint, by = "conus.grid.id") %>%
              full_join(climate, by = "conus.grid.id") %>%
              full_join(waterbody, by = "conus.grid.id") %>%
              full_join(traveltime, by = "conus.grid.id") %>%
              mutate(sqrtarea_small = sqrt(area_small),
                     sqrtarea_medium = sqrt(area_medium)) %>%
              select(conus.grid.id, sqrtarea_small, sqrtarea_medium, 
                     footprint, TRI, tmin, traveltime)
    
    covar <- covar[order(match(covar$conus.grid.id, region$sp.grid$conus.grid.id)),]
    write_rds(covar, file = paste0(data.dir, "covariates.rds"))
    
  }
  
}
```

Next we remove grid cells that do not have complete covariates.

```{r incomplete-covs}
## Remove incomplete cases
rm <- which(complete.cases(covar[,covs.z]) == F)
if (length(rm) > 0) {
  covar <- covar[-rm,]
  region$sp.grid <- region$sp.grid[-rm,]
}
```

Then we scale all covariates to have a mean of 1 and a standard deviation of 0.

```{r scale-covs}
## Scale covariates 
covar_unscaled <- covar
numcols <- sapply(covar, is.numeric)
numcols <- which(numcols)
covar[,numcols] <- sapply(covar[,numcols], scale_this)
```

Finally we create the quadratic covariates (as defined in `model-specs.csv`).

```{r quad-covs}
if (length(covs.quad) > 0 & paste0(covs.quad, collapse = "") != "") {
  for (c in 1:length(covs.quad)) {
    covar[,paste0(covs.quad[c], "2")] <- covar[,covs.quad[c]] * covar[,covs.quad[c]]
    covs.z <- c(covs.z, paste0(covs.quad[c], "2"))
  }
}
```


There's one additional step that could be done here. If removing multicollinearity is desired, the following piece of code would check and remove covariates that violate a 0.4 correlation threshold. If there are fewer than 3 covariates remaining after the procedure, then a message will alert you.

```{r collinearity, eval=F}
# remove covariates that are correlated > 0.4
if (check.covs == T){

  threshold <- 0.4
  if (sp.code == "PJOR") threshold <- 0.45

  covs.rm <- select_covar(covs.z, threshold = threshold)
  covs.lin <- covs.lin[-which(covs.lin %in% covs.rm)]
  covs.quad <- covs.quad[-which(covs.quad %in% covs.rm)]

  covs.z <- c(covs.lin, covs.quad)
}

if (length(covs.z) < 3) {
  stop("There are fewer than 3 covariates remaining! This probably isn't a good model")
}
```


## Step 6: Plot covariates

Now that we've downloaded covariate data, let's take a look at the distribution of each covariate and the correlations between them.

```{r plot-covs, results = 'hide'}
if (fold.out == "none") {
  
  ## Distribution covariates
  
  ## Define covariate labels
  covlabs <- read.csv("data/covariate-labels.csv") %>% filter(covariate %in% covs.z)
  
  plot_covar(covar,
             region,
             cov.names = covlabs$covariate,
             cov.labels = covlabs$Label,
             out.path = out.dir,
             out.name = "1_covariates-a_process-map")
  
  cor_covar(covar, 
            cov.names = covlabs$covariate,
            cov.labels = covlabs$Label,
            out.path = out.dir,
            out.name = "1_covariates-a_process-correlations", 
            color.threshold = 0.25)
  
  ## iNat covariates
  if ("iNaturalist" %in% names(species.data$obs)) {
    ## Define covariate labels
    covlabs <- read.csv("data/covariate-labels.csv") %>%
                filter(covariate %in% covs.inat)
    
    plot_covar(covar,
               region,
               cov.names = covlabs$covariate,
               cov.labels = covlabs$Label,
               out.path = out.dir,
               out.name = "1_covariates-b_iNat-map")
    
    if (length(covs.inat) > 1) {
      cor_covar(covar, 
                cov.names = covlabs$covariate,
                cov.labels = covlabs$Label,
                out.path = out.dir,
                out.name = "1_covariates-b_iNat-correlations", 
                color.threshold = 0.25)
    }
  }
  
  ## PO covs
  
  ## Define covariate labels
  covlabs <- read.csv("data/covariate-labels.csv") %>%
              filter(covariate %in% covs.PO)
  
  plot_covar(covar,
             region,
             cov.names = covlabs$covariate,
             cov.labels = covlabs$Label,
             out.path = out.dir,
             out.name = "1_covariates-c_PO-map")
  
  if (length(covs.PO) > 1) {
    cor_covar(covar, 
              cov.names = covlabs$covariate,
              cov.labels = covlabs$Label,
              out.path = out.dir,
              out.name = "1_covariates-c_PO-correlations", 
              color.threshold = 0.25)
  }
}
```


![Distribution of distribution-level covariates across the subrange](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/1_covariates-a_process-map.jpg)

![Correlation between distribution-level covariates](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/1_covariates-a_process-correlations.jpg)

![Distribution of presence-only (PO) effort covariates](C:/Users/rmummah/OneDrive - DOI/Documents/GitHub/iSDM-framework/outputs/3_RACA_subrange/1_covariates-c_PO-map.jpg)

## Step 7: NIMBLE

To load the data into NIMBLE, the data must be formatted in a specific way. We have wrapped this process in a function that combines and formats  species datasets (`allfiles`) and their associated covariates (contained in `allfiles`, `covs.inat`, and `covs.PO`)

```{r spdata}
sp.data <- sppdata_for_nimble(species.data,
                              region,
                              file.info = allfiles,
                              covar = covar,
                              covs.inat = covs.inat,
                              covs.PO = covs.PO,
                              DND.maybe = 1,  # treat "maybe" detections as 1 or 0?
                              # Only keep PO cells that training grid cells
                              keep.conus.grid.id = gridkey$conus.grid.id[which(gridkey$group == "train")]) 
```

Next, the distribution-level covariates (`covar`) are combined with the formatted species data. All of this is then broken into `data` and `constants` which are the inputs for the model.

```{r data-constants}
tmp <- data_for_nimble(sp.data, covar = covar, covs.z,
                       sp.auto = sp.auto, coarse.grid = coarse.grid, region = region,
                       process.intercept = F,
                       gridkey = gridkey, spatRegion = spatRegion)

data <- tmp$data
constants <- tmp$constants
```


The model structure allows for an indicator variable to indicate whether a cell is in a state with effort or not. There are generally two cases where this is useful: 

- If a state agency has collected PO only from within its state, by definition there is effort within that state but not outside of it. This information is already stored in `constants`, which pulled it from `allfiles$POextent`
- In iNaturalist data, if a species has taxon geoprivacy (i.e., obscured locations due to listing status) within a state, all records from that state will be removed by `load_species_data()` due to high coordinate uncertainty. The effort in that state is therefore effectively 0. 

The following code adds the state indicator variable to `constants`.

```{r state-indicator}

# GPOR has taxon geoprivacy in four states
if (sp.code == "GPOR") obsc.state <- c("CT", "MS", "NJ", "RI")

# RACA has no iNat data
if (sp.code == "RACA") obsc.state <- NA


constants <- add_state_ind(species.data,
                           region,
                           gridkey,
                           constants,
                           covs.inat = covs.inat,
                           obsc.state = obsc.state,
                           keep.conus.grid.id = gridkey$conus.grid.id[which(gridkey$group == "train")])
```


Once `data` and `constants` are set up for NIMBLE, the function `nimble_code()` writes the NIMBLE code using the information contained in those objects as well several other specificiations defined earlier in the code. The NIMBLE code is saved as a .R file in the location defined by the `path` argument, and in the object `code`.

```{r code}
code <- nimble_code(data,
                    constants, 
                    path = out.dir,
                    sp.auto = sp.auto, 
                    coarse.grid = coarse.grid,
                    Bprior = Bprior,
                    block.out = fold.out,
                    min.visits.incl = 3, 
                    zero_mean = zero_mean,
                    rm.state = F,
                    tau = tau)
```

Next, set up the initial values, also based on the information in `data` and `constants`.

```{r inits}
inits <- function(x){nimble_inits(data,
                                  constants,
                                  sp.auto = sp.auto,
                                  seed = x)}
```

Finally, identify which parameters the model should save chains for. By default, distribution model parameters ($B$) and dataset intercepts ($A$) are saved. Parameters that are estimated for each hexbin ($\lambda$, $XB$, effort) require more storage, so there are options to disable them. If `sp.auto = T`, then the spatial random effect and $\tau$ are also saved.

```{r params}
params <- nimble_params(data,
                        constants,
                        lambda = T,
                        XB = T,
                        effort = T,
                        sp.auto = sp.auto)
```


## Step 8: Clean up and save

Remove objects that are large and are not required for further steps, then save the workspace.

```{r clean-up}
# Remove local and fold in case the setup is run locally but the model is fit on the HPC.
# Remove other unnecessary files to reduce the size of setup_BLOCK.Rdata
rm(list=c('local','fold','args','conus.covar.grid','conus.grid','usa','conus',
          'pl','centroid'))


# Save environment and full set up
save.image(paste0(out.dir, "setup_",fold.out,".Rdata"))
```



<!-- # End script - proceed to 02-flexiSDM.R -->

<!-- ## --------------------------- -->
<!-- ## Objective:  -->
<!-- ##    - Fit NIMBLE model using setup_BLOCK.rdata file -->
<!-- ##  -->
<!-- ## Input: -->
<!-- ##    - setup_BLOCK.rdata -->
<!-- ## -->
<!-- ## Output:  -->
<!-- ##    - samples_BLOCK_CHAIN.rds OR samples_BLOCK.rds -->
<!-- ## -->
<!-- ## --------------------------- -->

# Part 2: 02-flexiSDM.R

```{r param.edit2, eval = F}
num <- 3
fold <- "none"
sp.code <- "RACA"
model <- "subrange"
chain <- 1
local <- 1
```


```{r load-packages2, results = 'hide', eval=F}
# Load functions and packages
source("functions/FXN-nimbleParallel.R") # HOW DO YOU RUN THIS IN ISDM-FRAMEWORK?
library(SpFut.flexiSDM)
```


```{r output-dir2, eval = F}
# Set output directory and load setup file
out.dir = paste0('outputs/',num,'_',sp.code,'_',model,'/')

load(paste0(out.dir,'setup_',fold,'.Rdata'))
```

## Fit NIMBLE model

```{r fit-nimble, eval=F}
if (local == 1) {
  start.nim <- Sys.time()
  samples <- nimbleParallel(code = code,
                            data = data,
                            constants = constants,
                            inits = inits,
                            param = params,
                            iter = iter,
                            burnin = burnin,
                            thin = thin)

  end.nim <- Sys.time() - start.nim
  print(end.nim)

  saveRDS(samples, paste0(out.dir,'samples_',fold,'.rds'))
} else {

  info <- list(seed = chain,
               inits = inits(chain))

  start.nim <- Sys.time()
  samples <- run_nimbleMCMC(info = info,
                            code = code,
                            constants = constants,
                            data = data,
                            param = params,
                            iter = iter,
                            burnin = burnin,
                            thin = thin)

  end.nim <- Sys.time() - start.nim
  print(end.nim)

  saveRDS(samples, paste0(out.dir,'samples_',fold,'_',chain,'.rds'))
}
```



# Part 3: 03-flexiSDM.R

<!-- <!-- ## --------------------------- --> -->
<!-- <!-- ## Objective:  --> -->
<!-- <!-- ##    - Fit NIMBLE model using setup_BLOCK.rdata file --> -->
<!-- <!-- ##  --> -->
<!-- <!-- ## Input: --> -->
<!-- <!-- ##    - setup_BLOCK.rdata --> -->
<!-- <!-- ##    - samples_BLOCK_CHAIN.rds OR samples_BLOCK.rds --> -->
<!-- <!-- ## --> -->
<!-- <!-- ## Output:  --> -->
<!-- <!-- ##    - samples_BLOCK_CHAIN.rds OR samples_BLOCK.rds --> -->
<!-- <!-- ## --> -->
<!-- <!-- ## --------------------------- --> -->


```{r load-packages3, results = 'hide', eval = F}
## load packages ----
library(tidyverse, quietly = T)
library(magrittr, quietly = T)
library(sf, quietly = T)
library(SpFut.flexiSDM)
```


```{r params.edit3, eval = F}
num <- 3
fold <- "none"
sp.code <- "RACA"
model <- "subrange"
maxchain <- 3
local <- 1
```



```{r out.dir3, eval = F}
# load output directory, setup, and functions
out.dir = paste0('outputs/',num,'_',sp.code,'_',model,'/')

load(paste0(out.dir,'setup_',fold,'.Rdata'))
```




```{r load-chains, eval = F}
# Load chains (samples) ----
samples <- readRDS(paste0(out.dir,'samples_',fold,'.rds'))

## Calculate derived quantities ----
# This takes longer with the coarse grid.
samples <- lapply(samples, get_derived, data = data, project = project,
                  coarse.grid = coarse.grid, spatRegion = spatRegion,
                  pathToProj = 'code/03-species-models/setup-projections.R')
```

```{r summarize-chains, eval = F}
## Summarize chains ----
out <- summarize_samples(samples,
                         data,
                         constants,
                         project = project,
                         coarse.grid = coarse.grid,
                         block.out = fold.out,
                         gridkey = gridkey,
                         spatkey = spatRegion$spatkey,
                         effort = T,
                         SLURM = ifelse(local == 1, F, T))

save(out, file = paste0(out.dir, "data", blockname, ".rdata"))
```


```{r plot-output, eval=F}
# Plot output ----

# Convergence
ggsave(plot_convergence(out),
       file = paste0(out.dir, "3_parameters-0_convergence-", fold, ".jpg"),
       height = 5, width = 12)

if (fold.out == "none") {
  cov.labs <- read.csv("data/covariate-labels.csv")

  ### Chains ----
  ggsave(plot_chains(samples, data = data, cov.labs = cov.labs,
                     plot = "B", cutoff = 0),
         file = paste0(out.dir, "3_parameters-a1_chains-B.jpg"),
         height = 6, width = 8)
  ggsave(plot_chains(samples, data = data, cov.labs = cov.labs,
                     plot = "alpha", cutoff = 0),
         file = paste0(out.dir, "3_parameters-b1_chains-alpha.jpg"),
         height = 6, width = 8)
  ggsave(plot_chains(samples, data = data, cov.labs = cov.labs,
                     plot = "tau", cutoff = 0),
         file = paste0(out.dir, "3_parameters-b1_chains-tau-",fold,".jpg"),
         height = 6, width = 8)

  # Posteriors ----
  ggsave(plot_posteriors(samples, data = data, cov.labs = cov.labs,
                         plot = "B", cutoff = 0),
         file = paste0(out.dir, "3_parameters-a2_posteriors-B.jpg"),
         height = 6, width = 8)
  ggsave(plot_posteriors(samples, data = data, cov.labs = cov.labs,
                         plot = "alpha", cutoff = 0),
         file = paste0(out.dir, "3_parameters-b2_posteriors-alpha.jpg"),
         height = 6, width = 8)



  ### Parameter estimates ----
  ggsave(plot_pars(out,
                   plot.type = "full",
                   plot.group = "process",
                   title = "Process parameter estimates",
                   cov.labs = cov.labs),
         file = paste0(out.dir, "3_parameters-a3_B.jpg"),
         height = 6, width = 10)

  ggsave(plot_pars(out,
                   plot.type = "full",
                   plot.group = "dataset",
                   title = "Dataset parameter estimates"),
         file = paste0(out.dir, "3_parameters-b3_alpha.jpg"),
         height = 6, width = 10)

  ggsave(plot_pars(out,
                   plot.type = "full",
                   plot.group = "observation",
                   title = "Observation intercept estimates",
                   cov.labs = cov.labs),
         file = paste0(out.dir, "3_parameters-c3_observation.jpg"),
         height = 6, width = 10)

  ggsave(plot_pars(out,
                   plot.type = "full",
                   plot.group = "tau",
                   title = "Tau estimate"),
         file = paste0(out.dir, "3_parameters-c3_tau.jpg"),
         height = 6, width = 10)

  ### Marginal effects ----
  ggsave(plot_effects(data, out, breaks = 0.001),
         file = paste0(out.dir, "/3_parameters-a4-effects.jpg"),
         height = 7, width = 10)


  ### Maps ----
  # Current
  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "lambda",
                         out = out)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-a_lambda.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "lambda",
                         out = out,
                         plot.uncertainty = "unc.range")
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-a_lambda-uncabs.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "lambda",
                         out = out,
                         plot.uncertainty = "unc.rel")
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-a_lambda-uncrel.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "psi",
                         out = out)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-b_psi.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "psi",
                         out = out,
                         plot.uncertainty = "unc.range")
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-b_psi-uncabs.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "psi",
                         out = out,
                         plot.uncertainty = "unc.rel")
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-b_psi-uncrel.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "boundary",
                         out = out,
                         threshold = 0.25)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-c1_boundary-0.25.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "boundary",
                         out = out,
                         threshold = 0.5)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-c2_boundary-0.5.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "boundary",
                         out = out,
                         threshold = 0.75)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-c3_boundary-0.75.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "spat",
                         out = out,
                         coarse.grid = coarse.grid,
                         spatRegion = spatRegion)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-d_spat.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "XB",
                         out = out,
                         plot.exp = T)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-d_expXB.jpg"),
         height = 7, width = 9)

  pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                         region,
                         plot = "effort",
                         out = out)
  ggsave(pl, file = paste0(out.dir, "4_mapcurrent-e_effort.jpg"),
         height = 7, width = 9)


  ### Future projections ----
  if (project > 0) {
    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-a_lambda.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           plot.uncertainty = "unc.range",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-a_lambda-uncabs.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           plot.uncertainty = "unc.rel",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-a_lambda-uncrel.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-b_psi.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           plot.uncertainty = "unc.range",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-b_psi-uncabs.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           plot.uncertainty = "unc.rel",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-b_psi-uncrel.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           threshold = 0.25,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-c1_boundary-0.25.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           threshold = 0.5,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-c2_boundary-0.5.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = F,
                           threshold = 0.75,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-c3_boundary-0.75.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "XB",
                           out = out,
                           plot.exp = T,
                           plot.current = F,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "5_mapfuture-d_expXB-future.jpg"),
           height = 7, width = 9)


    ### Future absolute change ----
    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-a1_lambda-abs.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-b1_psi-abs.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           threshold = 0.25,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-c1_boundary-abs-0.25.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           threshold = 0.5,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-c2_boundary-abs-0.5.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "boundary",
                           out = out,
                           plot.current = F,
                           plot.change = "absolute",
                           threshold = 0.75,
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-c3_boundary-abs-0.75.jpg"),
           height = 7, width = 9)

    ### Future relative change ----
    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "lambda",
                           out = out,
                           plot.current = F,
                           plot.change = "relative",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-a2_lambda-rel.jpg"),
           height = 7, width = 9)

    pl <- map_species_data(title = paste0(common, " (", sp.code, ")"),
                           region,
                           plot = "psi",
                           out = out,
                           plot.current = F,
                           plot.change = "relative",
                           proj.names = proj.names)
    ggsave(pl, file = paste0(out.dir, "6_mapchange-b2_psi-rel.jpg"),
           height = 7, width = 9)
  }
}
```


































# High performance computing

We almost exclusively run these models on a high performance computing (HPC) cluster. We clone our repository directly to the HPC to ensure we have the same file structure and no version conflicts. We've set up the code so we can seamlessly move between running the workflow locally and on our HPC. 

To run the first steps of the workflow via `01-flexiSDM.R`, we call the script `01-flexiSDM.sh`, which takes 3 inputs: 

- Model number
- fold (defined by an array in the script)
- Local (1/0)

We have simplified this further by writing a wrapper called `01-HPC.sh`, which only takes one input: model number. Within the script, `local` is set to 0, indicating a run on an HPC.

The inputs provided to the `.sh` scripts are converted to inputs to the `01-flexiSDM.R` script and are interpreted below:

```{r hpc, eval = F}
# Converts command arguments to something interpretable by R
args = commandArgs(trailingOnly = TRUE)

if (length(args) > 0) {

  # Model number to run
  nums.do = as.numeric(args[1])

  # Blocks can be run as single jobs or as arrays
  fold = as.numeric(args[2])
  
  # The fold input is numeric only. Convert 4 = 'none'
  if (fold == 4) {
    fold <- 'none'
  }

  # Running locally? Yes = 1
  local = as.numeric(args[3])

  # If running on an HPC, set the working directory to the project home directory
  if (local == 0) {
    setwd('/home/directory/')
  }
}
```




<!-- args = commandArgs(trailingOnly = TRUE) -->

<!-- if (length(args) > 0) { -->
<!--   num = as.numeric(args[1]) -->
<!--   sp.code = as.character(args[2]) -->
<!--   model = as.character(args[3]) -->
<!--   fold = as.numeric(args[4]) -->
<!--   chain = as.numeric(args[5]) -->
<!--   local = as.numeric(args[6])  -->

<!--   # If running on HPC, set working directory -->
<!--   if (local == 0) { -->
<!--     setwd('/caldera/hovenweep/projects/usgs/ecosystems/eesc/rmummah/species-futures/') -->
<!--   }  -->
<!-- } -->

<!-- # Ensure fold is coded correctly -->
<!-- if (fold == 4) { -->
<!--   fold <- 'none' -->
<!-- } -->




<!-- # Setup ---- -->
<!-- args = commandArgs(trailingOnly = TRUE) -->

<!-- if (length(args) > 0) { -->
<!--   num = as.numeric(args[1]) -->
<!--   sp.code = as.character(args[2]) -->
<!--   model = as.character(args[3]) -->
<!--   fold = as.numeric(args[4]) -->
<!--   maxchain = as.numeric(args[5]) -->
<!--   local = as.numeric(args[6]) -->

<!--   if (local == 0) { -->
<!--     setwd('/caldera/hovenweep/projects/usgs/ecosystems/eesc/rmummah/species-futures/') -->
<!--   }  -->

<!-- } -->

<!-- # Ensure fold is coded correctly -->
<!-- if (fold == 4) { -->
<!--   fold <- 'none' -->
<!-- } -->